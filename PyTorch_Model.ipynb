{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Stuff.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMDzbdEARGSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "d455755c-4fa4-44de-bc4d-96ee1a8b634a"
      },
      "source": [
        "%pip install billboard.py\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting billboard.py\n",
            "  Downloading https://files.pythonhosted.org/packages/3a/3a/2019c4211af034a06468acebc0c8f1027e633326d21fae92b6be214bb04e/billboard.py-6.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from billboard.py) (4.6.3)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from billboard.py) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->billboard.py) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->billboard.py) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->billboard.py) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->billboard.py) (3.0.4)\n",
            "Installing collected packages: billboard.py\n",
            "Successfully installed billboard.py-6.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MivEM2JXDJAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import billboard\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import datetime\n",
        "import random\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3_QIWZDSHYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04876332-b227-4ce6-e611-01d35e60e6ac"
      },
      "source": [
        "charts = []\n",
        "charts.append(billboard.ChartData('hot-100'))\n",
        "while len(charts) < 100:\n",
        "  charts.insert(0, billboard.ChartData('hot-100', charts[0].previousDate))\n",
        "  print('\\r', len(charts), end=\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 100"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RTJfhXXfgCS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "724e2a51-e198-46e2-96a5-19352344fadb"
      },
      "source": [
        "print(vars(charts[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'title': 'In My Feelings', 'artist': 'Drake', 'image': None, 'peakPos': 1, 'lastPos': 1, 'weeks': 11, 'rank': 1, 'isNew': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HrCDMOmzQql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf76ea30-3451-4ad2-ca96-cc691adc8cf9"
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "artists = {}\n",
        "\n",
        "for i in range(len(charts) - 1):\n",
        "  x_train.append([])\n",
        "  y_train.append([])\n",
        "  for song in charts[i]:\n",
        "    if song.artist not in artists:\n",
        "      artists[song.artist] = random.random() * 10\n",
        "    x_train[-1].extend([artists[song.artist], song.peakPos, song.lastPos, song.weeks, song.rank, song.isNew])\n",
        "    found = False\n",
        "    for c in charts[i+1]:\n",
        "      if c.title == song.title:\n",
        "        y_train[-1].append(c.rank)\n",
        "        found = True\n",
        "        break\n",
        "    if not found:\n",
        "      y_train[-1].append(101)\n",
        "\n",
        "\n",
        "  #   if song in charts[i+1]:\n",
        "  #     print('sc')\n",
        "  # for song in charts[i+1]:\n",
        "  #   if song.artist not in artists:\n",
        "  #     artists[song.artist] = random.random() * 10\n",
        "  #   y_train[-1].append(song.rank)\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(99, 600) (99, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S9rK0hxDPCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[0:4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq9clRh2Whsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, in_size=64):\n",
        "      super(Network, self).__init__()\n",
        "      # 300 -> 300 -> batch norm -> dropout -> 150 -> 150 -> batch norm -> dropout -> 100 -> 100\n",
        "      self.l1 = nn.Linear(in_size, 300)\n",
        "      self.l2 = nn.Linear(300, 300)\n",
        "      self.l3 = nn.BatchNorm1d(300, track_running_stats=False)\n",
        "      self.l4 = nn.Dropout(0.5)\n",
        "      self.l5 = nn.Linear(300, 150)\n",
        "      self.l6 = nn.Linear(150, 150)\n",
        "      self.l7 = nn.BatchNorm1d(150, track_running_stats=False)\n",
        "      self.l8 = nn.Dropout(0.5)\n",
        "      self.l9 = nn.Linear(150, 100)\n",
        "      self.l10 = nn.Linear(100, 100) \n",
        "\n",
        "    def forward(self, x):\n",
        "      x = F.relu(self.l1(x))\n",
        "      x = F.relu(self.l2(x))\n",
        "      x = self.l3(x)\n",
        "      x = self.l4(x)\n",
        "      x = F.relu(self.l5(x))\n",
        "      x = F.relu(self.l6(x))\n",
        "      x = self.l7(x)\n",
        "      x = self.l8(x)\n",
        "      x = F.relu(self.l9(x))\n",
        "      x = F.relu(self.l10(x))\n",
        "\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cTF4STunn7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Network(600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E81cYIr9nve6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(net.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv6BlEP71Ia4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f38cbb1-1ced-4464-abd5-6d50f605ad77"
      },
      "source": [
        "import math\n",
        "import time\n",
        "batchsize = 4\n",
        "bestLoss = 1e15\n",
        "for epoch in range(400):  # loop over the dataset multiple times\n",
        "  startTime = time.time()\n",
        "  num = len(x_train)\n",
        "  running_loss = 0.0\n",
        "  for i in range(0, len(x_train), batchsize):\n",
        "\n",
        "    e = min(i + batchsize, len(x_train))\n",
        "    inputs = torch.FloatTensor(x_train[i:e])\n",
        "    y = torch.FloatTensor(y_train[i:e])\n",
        "\n",
        "    labels = y\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    losses = []\n",
        "    for o in range(len(outputs)):\n",
        "      losses.append(criterion(outputs[o], y[o]))\n",
        "    loss = losses[0]\n",
        "    for l in losses[1:]: loss = loss + l\n",
        "    # loss = criterion(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    dif = time.time()-startTime\n",
        "    eta = round(dif/(i+1) * num - dif)\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    # print('\\r', 'epoch', epoch, str(i) + '/' + str(num) + ', eta:', eta, ', loss:', round(running_loss / batchsize, 3), end=\"\")\n",
        "  # print()\n",
        "  print('\\r', 'epoch', epoch, str(i) + '/' + str(num) + ', Time:', round(time.time() - startTime), ', loss:', running_loss / batchsize, end=\"\")\n",
        "  if running_loss < bestLoss:\n",
        "    torch.save(net.state_dict(), 'best.pt')\n",
        "    print('\\nsaved', running_loss/batchsize)\n",
        "    bestLoss = running_loss\n",
        "\n",
        "\n",
        "print('\\nFinished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r epoch 0 96/99, Time: 0 , loss: 100419.51025390625\n",
            "saved 100419.51025390625\n",
            "\r epoch 1 96/99, Time: 0 , loss: 97937.05200195312\n",
            "saved 97937.05200195312\n",
            " epoch 2 96/99, Time: 0 , loss: 91597.05834960938\n",
            "saved 91597.05834960938\n",
            " epoch 3 96/99, Time: 0 , loss: 70521.64428710938\n",
            "saved 70521.64428710938\n",
            " epoch 4 96/99, Time: 0 , loss: 33818.58544921875\n",
            "saved 33818.58544921875\n",
            " epoch 5 96/99, Time: 0 , loss: 17524.03778076172\n",
            "saved 17524.03778076172\n",
            " epoch 6 96/99, Time: 0 , loss: 10237.187850952148\n",
            "saved 10237.187850952148\n",
            " epoch 7 96/99, Time: 0 , loss: 8047.673858642578\n",
            "saved 8047.673858642578\n",
            " epoch 8 96/99, Time: 0 , loss: 7287.564071655273\n",
            "saved 7287.564071655273\n",
            " epoch 10 96/99, Time: 0 , loss: 7058.025360107422\n",
            "saved 7058.025360107422\n",
            " epoch 12 96/99, Time: 0 , loss: 6913.825881958008\n",
            "saved 6913.825881958008\n",
            " epoch 16 96/99, Time: 0 , loss: 6760.942489624023\n",
            "saved 6760.942489624023\n",
            " epoch 20 96/99, Time: 0 , loss: 6533.536468505859\n",
            "saved 6533.536468505859\n",
            " epoch 40 96/99, Time: 0 , loss: 6510.322036743164\n",
            "saved 6510.322036743164\n",
            " epoch 54 96/99, Time: 0 , loss: 6451.31640625\n",
            "saved 6451.31640625\n",
            " epoch 91 96/99, Time: 0 , loss: 6408.179473876953\n",
            "saved 6408.179473876953\n",
            " epoch 95 96/99, Time: 0 , loss: 6374.2744140625\n",
            "saved 6374.2744140625\n",
            " epoch 107 96/99, Time: 0 , loss: 6204.2567138671875\n",
            "saved 6204.2567138671875\n",
            " epoch 210 96/99, Time: 0 , loss: 6135.350570678711\n",
            "saved 6135.350570678711\n",
            " epoch 214 96/99, Time: 0 , loss: 6010.132064819336\n",
            "saved 6010.132064819336\n",
            " epoch 238 96/99, Time: 0 , loss: 5970.9615478515625\n",
            "saved 5970.9615478515625\n",
            " epoch 245 96/99, Time: 0 , loss: 5830.21076965332\n",
            "saved 5830.21076965332\n",
            " epoch 257 96/99, Time: 0 , loss: 5758.634864807129\n",
            "saved 5758.634864807129\n",
            " epoch 263 96/99, Time: 0 , loss: 5744.840896606445\n",
            "saved 5744.840896606445\n",
            " epoch 273 96/99, Time: 0 , loss: 5652.2647705078125\n",
            "saved 5652.2647705078125\n",
            " epoch 291 96/99, Time: 0 , loss: 5595.964111328125\n",
            "saved 5595.964111328125\n",
            " epoch 297 96/99, Time: 0 , loss: 5542.5821533203125\n",
            "saved 5542.5821533203125\n",
            " epoch 301 96/99, Time: 0 , loss: 5503.472579956055\n",
            "saved 5503.472579956055\n",
            " epoch 323 96/99, Time: 0 , loss: 5501.680160522461\n",
            "saved 5501.680160522461\n",
            " epoch 329 96/99, Time: 0 , loss: 5421.06916809082\n",
            "saved 5421.06916809082\n",
            " epoch 358 96/99, Time: 0 , loss: 5382.561561584473\n",
            "saved 5382.561561584473\n",
            " epoch 372 96/99, Time: 0 , loss: 5328.756942749023\n",
            "saved 5328.756942749023\n",
            " epoch 375 96/99, Time: 0 , loss: 5286.0600662231445\n",
            "saved 5286.0600662231445\n",
            " epoch 381 96/99, Time: 0 , loss: 5247.081680297852\n",
            "saved 5247.081680297852\n",
            " epoch 396 96/99, Time: 0 , loss: 5190.190132141113\n",
            "saved 5190.190132141113\n",
            " epoch 399 96/99, Time: 0 , loss: 5317.618225097656\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj5mylrH7lKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(net(torch.FloatTensor(x_train[0:4])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtadKBRc_aUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.save(net, 'trainedNet.pth')\n",
        "with open('artists.pickle', 'wb') as handle:\n",
        "    pickle.dump(artists, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd3XsHjQA5f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Network(600)\n",
        "model = model.load_state_dict('bestNet.pt')\n",
        "model.eval()\n",
        "ex = torch.FloatTensor(np.array([x_train[-1], x_train[-1]]))\n",
        "results = model(ex)[0]\n",
        "print(results)\n",
        "print(np.argsort(list(results)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxDKZcTAEAu4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "cbbef38a-0dcb-4197-d2f9-d321d08372d5"
      },
      "source": [
        "# outputs = model(get_next())[0]\n",
        "newPos = np.argsort(list(results))\n",
        "ranking = []\n",
        "for p in newPos:\n",
        "  ranking.append(charts[-2][p])\n",
        "\n",
        "for i in range(10):\n",
        "  print(ranking[i], '||||', charts[-1][i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Cardigan' by Taylor Swift |||| 'Watermelon Sugar' by Harry Styles\n",
            "'Whats Poppin' by Jack Harlow Featuring DaBaby, Tory Lanez & Lil Wayne |||| 'Rockstar' by DaBaby Featuring Roddy Ricch\n",
            "'Rockstar' by DaBaby Featuring Roddy Ricch |||| 'Whats Poppin' by Jack Harlow Featuring DaBaby, Tory Lanez & Lil Wayne\n",
            "'Blinding Lights' by The Weeknd |||| 'Blinding Lights' by The Weeknd\n",
            "'Exile' by Taylor Swift Featuring Bon Iver |||| 'Roses' by SAINt JHN\n",
            "'The 1' by Taylor Swift |||| 'My Future' by Billie Eilish\n",
            "'Roses' by SAINt JHN |||| 'Savage Love (Laxed - Siren Beat)' by Jawsh 685 x Jason Derulo\n",
            "'Watermelon Sugar' by Harry Styles |||| 'Cardigan' by Taylor Swift\n",
            "'Savage' by Megan Thee Stallion Featuring Beyonce |||| 'Go Crazy' by Chris Brown & Young Thug\n",
            "'Savage Love (Laxed - Siren Beat)' by Jawsh 685 x Jason Derulo |||| 'Blueberry Faygo' by Lil Mosey\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNGAVVtEFT2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import billboard\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, time\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "charts = []\n",
        "charts.append(billboard.ChartData('hot-100'))\n",
        "charts.append(billboard.ChartData('hot-100', charts[0].previousDate))\n",
        "\n",
        "previous = charts[0][:10]\n",
        "current = charts[1][:10]\n",
        "\n",
        "model = Network(600)\n",
        "model.load_state_dict(torch.load('best.pt'))\n",
        "model.eval()\n",
        "\n",
        "artistFile = open('artists.pickle', 'rb')\n",
        "artists = pickle.load(artistFile)\n",
        "\n",
        "def get_next():\n",
        "\tx = []\n",
        "\n",
        "\tfor song in charts[1]:\n",
        "\t\tx.extend([artists[song.artist], song.peakPos, song.lastPos, song.weeks, song.rank, song.isNew])\n",
        "\n",
        "\treturn torch.FloatTensor(np.array([x, x]))\n",
        "\n",
        "def predict():\n",
        "\toutputs = model(get_next())[0]\n",
        "\tnewPos = np.argsort(list(outputs))\n",
        "\tranking = []\n",
        "\tfor p in newPos:\n",
        "\t\tranking.append(charts[1][p])\n",
        "\t\n",
        "\treturn ranking"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsckBJX5UjQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import billboard\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, time\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, in_size=64):\n",
        "      super(Network, self).__init__()\n",
        "      # 300 -> 300 -> batch norm -> dropout -> 150 -> 150 -> batch norm -> dropout -> 100 -> 100\n",
        "      self.l1 = nn.Linear(in_size, 300)\n",
        "      self.l2 = nn.Linear(300, 300)\n",
        "      self.l3 = nn.BatchNorm1d(300, track_running_stats=False)\n",
        "      self.l4 = nn.Dropout(0.5)\n",
        "      self.l5 = nn.Linear(300, 150)\n",
        "      self.l6 = nn.Linear(150, 150)\n",
        "      self.l7 = nn.BatchNorm1d(150, track_running_stats=False)\n",
        "      self.l8 = nn.Dropout(0.5)\n",
        "      self.l9 = nn.Linear(150, 100)\n",
        "      self.l10 = nn.Linear(100, 100) \n",
        "\n",
        "    def forward(self, x):\n",
        "      x = F.relu(self.l1(x))\n",
        "      x = F.relu(self.l2(x))\n",
        "      x = self.l3(x)\n",
        "      x = self.l4(x)\n",
        "      x = F.relu(self.l5(x))\n",
        "      x = F.relu(self.l6(x))\n",
        "      x = self.l7(x)\n",
        "      x = self.l8(x)\n",
        "      x = F.relu(self.l9(x))\n",
        "      x = F.relu(self.l10(x))\n",
        "\n",
        "      return x\n",
        "\n",
        "charts = []\n",
        "charts.append(billboard.ChartData('hot-100'))\n",
        "charts.append(billboard.ChartData('hot-100', charts[0].previousDate))\n",
        "\n",
        "previous = charts[0][:10]\n",
        "current = charts[1][:10]\n",
        "\n",
        "model = Network(600)\n",
        "model.load_state_dict(torch.load('best.pt'))\n",
        "model.eval()\n",
        "\n",
        "artistFile = open('artists.pickle', 'rb')\n",
        "artists = pickle.load(artistFile)\n",
        "\n",
        "def get_next():\n",
        "\tx = []\n",
        "\n",
        "\tfor song in charts[1]:\n",
        "\t\tx.extend([artists[song.artist], song.peakPos, song.lastPos, song.weeks, song.rank, song.isNew])\n",
        "\n",
        "\treturn torch.FloatTensor(np.array([x, x]))\n",
        "\n",
        "def predict():\n",
        "\toutputs = model(get_next())[0]\n",
        "\tnewPos = np.argsort(list(outputs))\n",
        "\tranking = []\n",
        "\tfor p in newPos:\n",
        "\t\tranking.append(charts[1][p])\n",
        "\t\n",
        "\treturn ranking"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}